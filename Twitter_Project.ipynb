{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 1 : Collecting Data from Twitter\n",
    "\n",
    "Due Date: September 22, **before the beginning of class at 6:00pm**\n",
    "\n",
    "* ------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/9/9f/Twitter_bird_logo_2012.svg/220px-Twitter_bird_logo_2012.svg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEAM Members:** Please EDIT this cell and add the names of all the team members in your team\n",
    "\n",
    "    Dhaval Dholakia\n",
    "    \n",
    "    Deepan Sanghavi\n",
    "    \n",
    "    Karan Somaiah Napanda\n",
    "    \n",
    "    Rohitpal Singh\n",
    "    \n",
    "    Bhakti Chheda\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required Readings:** \n",
    "* Chapter 1 and Chapter 9 of the book [Mining the Social Web](http://www.learndatasci.com/wp-content/uploads/2015/08/Mining-the-Social-Web-2nd-Edition.pdf) \n",
    "* The codes for [Chapter 1](http://bit.ly/1qCtMrr) and [Chapter 9](http://bit.ly/1u7eP33)\n",
    "\n",
    "\n",
    "** NOTE **\n",
    "* Please don't forget to save the notebook frequently when working in IPython Notebook, otherwise the changes you made can be lost.\n",
    "\n",
    "*----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Sampling Twitter Data with Streaming API about a certain topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select a topic that you are interested in, for example, \"WPI\" or \"Lady Gaga\"\n",
    "* Use Twitter Streaming API to sample a collection of tweets about this topic in real time. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million.\n",
    "* Store the tweets you downloaded into a local file (txt file or json file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded.... 1 \n",
      "Downloaded.... 2 \n",
      "Downloaded.... 3 \n",
      "Downloaded.... 4 \n",
      "Downloaded.... 5 \n",
      "Downloaded.... 6 \n",
      "Downloaded.... 7 \n",
      "Downloaded.... 8 \n",
      "Downloaded.... 9 \n",
      "Downloaded.... 10 \n",
      "Downloaded.... 11 \n",
      "Downloaded.... 12 \n",
      "Downloaded.... 13 \n",
      "Downloaded.... 14 \n",
      "Downloaded.... 15 \n",
      "Downloaded.... 16 \n",
      "Downloaded.... 17 \n",
      "Downloaded.... 18 \n",
      "Downloaded.... 19 \n",
      "Downloaded.... 20 \n",
      "Downloaded.... 21 \n",
      "Downloaded.... 22 \n",
      "Downloaded.... 23 \n",
      "Downloaded.... 24 \n",
      "Downloaded.... 25 \n",
      "Downloaded.... 26 \n",
      "Downloaded.... 27 \n",
      "Downloaded.... 28 \n",
      "Downloaded.... 29 \n",
      "Downloaded.... 30 \n",
      "Downloaded.... 31 \n",
      "Downloaded.... 32 \n",
      "Downloaded.... 33 \n",
      "Downloaded.... 34 \n",
      "Downloaded.... 35 \n",
      "Downloaded.... 36 \n",
      "Downloaded.... 37 \n",
      "Downloaded.... 38 \n",
      "Downloaded.... 39 \n",
      "Downloaded.... 40 \n",
      "Downloaded.... 41 \n",
      "Downloaded.... 42 \n",
      "Downloaded.... 43 \n",
      "Downloaded.... 44 \n",
      "Downloaded.... 45 \n",
      "Downloaded.... 46 \n",
      "Downloaded.... 47 \n",
      "Downloaded.... 48 \n",
      "Downloaded.... 49 \n",
      "Downloaded.... 50 \n",
      "Downloaded.... 51 \n",
      "Downloaded.... 52 \n",
      "Downloaded.... 53 \n",
      "Downloaded.... 54 \n",
      "Downloaded.... 55 \n",
      "Downloaded.... 56 \n",
      "Downloaded.... 57 \n",
      "Downloaded.... 58 \n",
      "Downloaded.... 59 \n",
      "Downloaded.... 60 \n",
      "Downloaded.... 61 \n",
      "Downloaded.... 62 \n",
      "Downloaded.... 63 \n",
      "Downloaded.... 64 \n",
      "Downloaded.... 65 \n",
      "Downloaded.... 66 \n",
      "Downloaded.... 67 \n",
      "Downloaded.... 68 \n",
      "Downloaded.... 69 \n",
      "Downloaded.... 70 \n",
      "Downloaded.... 71 \n",
      "Downloaded.... 72 \n",
      "Downloaded.... 73 \n",
      "Downloaded.... 74 \n",
      "Downloaded.... 75 \n",
      "Downloaded.... 76 \n",
      "Downloaded.... 77 \n",
      "Downloaded.... 78 \n",
      "Downloaded.... 79 \n",
      "Downloaded.... 80 \n",
      "Downloaded.... 81 \n",
      "Downloaded.... 82 \n",
      "Downloaded.... 83 \n",
      "Downloaded.... 84 \n",
      "Downloaded.... 85 \n",
      "Downloaded.... 86 \n",
      "Downloaded.... 87 \n",
      "Downloaded.... 88 \n",
      "Downloaded.... 89 \n",
      "Downloaded.... 90 \n",
      "Downloaded.... 91 \n",
      "Downloaded.... 92 \n",
      "Downloaded.... 93 \n",
      "Downloaded.... 94 \n",
      "Downloaded.... 95 \n",
      "Downloaded.... 96 \n",
      "Downloaded.... 97 \n",
      "Downloaded.... 98 \n",
      "Downloaded.... 99 \n",
      "Downloaded.... 100 \n",
      "Downloaded.... 101 \n",
      "Downloaded.... 102 \n",
      "Downloaded.... 103 \n",
      "Downloaded.... 104 \n",
      "Downloaded.... 105 \n",
      "Downloaded.... 106 \n",
      "Downloaded.... 107 \n",
      "Downloaded.... 108 \n",
      "Downloaded.... 109 \n",
      "Downloaded.... 110 \n",
      "Downloaded.... 111 \n",
      "Downloaded.... 112 \n",
      "Downloaded.... 113 \n",
      "Downloaded.... 114 \n",
      "Downloaded.... 115 \n",
      "Downloaded.... 116 \n",
      "Downloaded.... 117 \n",
      "Downloaded.... 118 \n",
      "Downloaded.... 119 \n",
      "Downloaded.... 120 \n",
      "Downloaded.... 121 \n",
      "Downloaded.... 122 \n",
      "Downloaded.... 123 \n",
      "Downloaded.... 124 \n",
      "Downloaded.... 125 \n",
      "Downloaded.... 126 \n",
      "Downloaded.... 127 \n",
      "Downloaded.... 128 \n",
      "Downloaded.... 129 \n",
      "Downloaded.... 130 \n",
      "Downloaded.... 131 \n",
      "Downloaded.... 132 \n",
      "Downloaded.... 133 \n",
      "Downloaded.... 134 \n",
      "Downloaded.... 135 \n",
      "Downloaded.... 136 \n",
      "Downloaded.... 137 \n",
      "Downloaded.... 138 \n",
      "Downloaded.... 139 \n",
      "Downloaded.... 140 \n",
      "Downloaded.... 141 \n",
      "Downloaded.... 142 \n",
      "Downloaded.... 143 \n",
      "Downloaded.... 144 \n",
      "Downloaded.... 145 \n",
      "Downloaded.... 146 \n",
      "Downloaded.... 147 \n",
      "Downloaded.... 148 \n",
      "Downloaded.... 149 \n",
      "Downloaded.... 150 \n",
      "Downloaded.... 151 \n",
      "Downloaded.... 152 \n",
      "Downloaded.... 153 \n",
      "Downloaded.... 154 \n",
      "Downloaded.... 155 \n",
      "Downloaded.... 156 \n",
      "Downloaded.... 157 \n",
      "Downloaded.... 158 \n",
      "Downloaded.... 159 \n",
      "Downloaded.... 160 \n",
      "Downloaded.... 161 \n",
      "Downloaded.... 162 \n",
      "Downloaded.... 163 \n",
      "Downloaded.... 164 \n",
      "Downloaded.... 165 \n",
      "Downloaded.... 166 \n",
      "Downloaded.... 167 \n",
      "Downloaded.... 168 \n",
      "Downloaded.... 169 \n",
      "Downloaded.... 170 \n",
      "Downloaded.... 171 \n"
     ]
    }
   ],
   "source": [
    "# import twitter\n",
    "# #---------------------------------------------\n",
    "# # Define a Function to Login Twitter API\n",
    "# def oauth_login():\n",
    "#     # Go to http://twitter.com/apps/new to create an app and get values\n",
    "#     # for these credentials that you'll need to provide in place of these\n",
    "#     # empty string values that are defined as placeholders.\n",
    "#     # See https://dev.twitter.com/docs/auth/oauth for more information \n",
    "#     # on Twitter's OAuth implementation.\n",
    "    \n",
    "#     CONSUMER_KEY = '<Insert your key>'\n",
    "#     CONSUMER_SECRET ='<Insert your key>'\n",
    "#     OAUTH_TOKEN = '<Insert your token>'\n",
    "#     OAUTH_TOKEN_SECRET = '<Insert your token>'\n",
    "    \n",
    "#     auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "#                                CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    \n",
    "#     twitter_api = twitter.Twitter(auth=auth)\n",
    "#     return twitter_api\n",
    "\n",
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "\n",
    "#this code extracts tweets based on the search query of the user. To extract more than 200 tweets we have introduced a while \n",
    "# loop and maintained the count of number of tweets that are downloaded, and as twitter has a limit of providing 3000 tweets i\n",
    "# a timeframe of 15 minutes, we introduce sleep of 15 minutes once 2900 tweets have been downloaded\n",
    "\n",
    "from tweepy import *\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk import *\n",
    "import re\n",
    "consumer_key='Ue8YXvxgX0Drt2aBnbBvvLTwK'\n",
    "consumer_secret='V1M1RsV5LhEc2DJS5Gb5HrWhnH2GLEvcDGvFpzR3uopvzZddnX'\n",
    "access_token='1256709506-0yCZNrYdcxySWzPFkbPcmkNaCKGsNKNbvPAHdnk'\n",
    "access_secret='bV85NMkAXG7tbhFij7lpgTLmRHrXS0K1yQsMXcYZxA8He'\n",
    "auth=OAuthHandler(consumer_key,consumer_secret)\n",
    "auth.set_access_token(access_token,access_secret)\n",
    "api=API(auth)\n",
    "search_result = Cursor(api.search, q='pokemon robbery',count=200).items()\n",
    "x=0\n",
    "f=open('twitter_data_Pokemon_GO_rob.csv','w')\n",
    "writer=csv.writer(f)\n",
    "tweets=[]\n",
    "while True:\n",
    "    try:\n",
    "        x=x+1\n",
    "        user=next(search_result)\n",
    "        tweets.append(user.text)\n",
    "        processed_text=user.text.encode('utf-8').replace(\",\",\"\")\n",
    "        print \"Downloaded.... %s \"%(len(tweets))\n",
    "        list=[processed_text,user.created_at.strftime('%m/%d/%Y %H:%M'),str(user.retweet_count),str(user.favorite_count),user.user.time_zone]\n",
    "        # writer.writerow(processed_text+','+user.created_at.strftime('%m/%d/%Y %H:%M')+','+str(user.retweet_count)+','+str(user.favorite_count))\n",
    "        writer.writerow(list)\n",
    "        if x>2900:\n",
    "            x=0\n",
    "            time.sleep(900)\n",
    "    except (TweepError) as ex:\n",
    "        time.sleep(60*16)\n",
    "        pass\n",
    "    except StopIteration:\n",
    "        break\n",
    "\n",
    "\n",
    "# tweets downloaded on the basis of search queries :\n",
    "# query: pokemon accidents number of tweets : 526\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tweepy import *\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report some statistics about the tweets you collected \n",
    "\n",
    "* The topic of interest: Pokemon accidents\n",
    "\n",
    "\n",
    "* The total number of tweets collected:  529\n",
    "\n",
    "* The topic of interest: Pokemon robbery\n",
    "\n",
    "\n",
    "* The total number of tweets collected:  170\n",
    "\n",
    "* The topic of interest: Pokemon hate\n",
    "\n",
    "\n",
    "* The total number of tweets collected:  626\n",
    "\n",
    "* The topic of interest: Pokemon Love\n",
    "\n",
    "\n",
    "* The total number of tweets collected:  2330\n",
    "\n",
    "\n",
    "* The topic of interest: #DontCatchandDrive\n",
    "\n",
    "\n",
    "* The total number of tweets collected:  111\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Analyzing Tweets and Tweet Entities with Frequency Analysis\n",
    "\n",
    "**1. Word Count:** \n",
    "* Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets. \n",
    "* Plot a table of the top 30 words with their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "file = open('/home/dhaval/Dhaval/Data Science/Projects/DS-501/Case Study 1/twitter_data_Pokemon_GO.txt',\"r\")\n",
    "for line in file:\n",
    "    try:\n",
    "        tweet=json.loads(line)\n",
    "        data.append(tweet)\n",
    "    except:\n",
    "        continue\n",
    "#print len(data)\n",
    "# print data[0].keys()\n",
    "# exit(1)\n",
    "# print data[0]['entities']['user_mentions']['screen_name']\n",
    "# exit(0)\n",
    "entitieslist=[]\n",
    "# for i in data['entities']:\n",
    "#     temp=json.loads(line)\n",
    "#     entitieslist.append(temp)\n",
    "\n",
    "#print \"Retweets :  \",data[50]['retweet_count']\n",
    "data2=json_normalize(data)\n",
    "# print data2['favorite_count']\n",
    "# exit(0)\n",
    "finalData=data2[['user.screen_name','id','timestamp_ms','text','retweet_count','favorite_count','place','coordinates','lang','created_at']]\n",
    "finalData=finalData.loc[finalData['lang']==\"en\"]\n",
    "\n",
    "\n",
    "processed_sentences=[]\n",
    "for i in finalData['text']:\n",
    "    #print i\n",
    "    #print '\\n'\n",
    "    #print \"-----------------------------------------------------------------------\"\n",
    "    processed_sentences.append(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",i))\n",
    "    #print words\n",
    "    #exit(1)\n",
    "    #words.extend(word_tokenize(i))\n",
    "temp=[]\n",
    "for x in processed_sentences:\n",
    "    temp.append(x.lower())\n",
    "processed_sentences=temp\n",
    "# print processed_sentences[0]\n",
    "words=[]\n",
    "for i  in processed_sentences:\n",
    "    tokenized_words=word_tokenize(i)\n",
    "    for j in tokenized_words:\n",
    "        words.append(j)\n",
    "\n",
    "#print words[0]\n",
    "filtered_sentence=[]\n",
    "stop_words=stopwords.words(\"english\")+['RT','via','pokemon','go','am','pm','pok','mon','do']\n",
    "for i in words:\n",
    "    if i not in stop_words:\n",
    "        if any(char.isdigit() for char in i)==False:\n",
    "            filtered_sentence.append(i)\n",
    "\n",
    "#print \"Done!!\"\n",
    "#print filtered_sentence\n",
    "#exit(1)\n",
    "counter.update(filtered_sentence)\n",
    "print counter.most_common(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Find the most popular tweets in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "#Get top 10 popular tweets\n",
    "print finalData.sort('retweet_count',ascending=False).head(10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Find the most popular Tweet Entities in your collection of tweets**\n",
    "\n",
    "Please plot a table of the top 10 hashtags, top 10 user mentions that are the most popular in your collection of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "hashtags=[]\n",
    "user_mentions=[]\n",
    "mentions_counter=Counter()\n",
    "for i in finalData['text']:\n",
    "    for j in i.split():\n",
    "        if j.startswith(\"#\"):\n",
    "            hashtags.append(j.lower())\n",
    "\n",
    "for i in finalData['text']:\n",
    "    for j in i.split():\n",
    "        if j.startswith(\"@\"):\n",
    "            user_mentions.append(j.lower())\n",
    "\n",
    "print \"hashtags : \",len(hashtags), len(finalData['text'])\n",
    "hashtagsCounter.update(hashtags)\n",
    "mentions_counter.ipdate(user_mentions)\n",
    "print hashtagsCounter.most_common(50)\n",
    "print mentions_counter.most_common(50)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ------------------------\n",
    "\n",
    "# Problem 3: Getting \"All\" friends and \"All\" followers of a popular user in twitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "* Get the list of all friends and all followers of the twitter user.\n",
    "* Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "* Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "#Following NateSilver and we got 'All' followers i.e around 60000 and counting\n",
    "\n",
    "import tweepy\n",
    "import tweepy.error\n",
    "import time\n",
    "from requests.exceptions import Timeout, ConnectionError\n",
    "from requests.packages.urllib3.exceptions import ReadTimeoutError\n",
    "#---------------------------------------------\n",
    "# Define a Function to Login Twitter API\n",
    "def oauth_login():\n",
    "    global api\n",
    "    auth = tweepy.OAuthHandler('bGCHZfPeuZ5YT6K1sKgQAEc3i','30WeyVyJBXH4I2VurEahvxVnfgIS6ID28a19659da8u8Fjy8j6' )\n",
    "    auth.set_access_token('833717288-1SOnSQSwRxxa3pRypHrYicro3t8rEvmPbKTm0hay','vAi4UscaZZ78awDpkdnd7ZFTzKTRovrM6wi0SlVmKz8Mn')\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "def follow(): \n",
    "    i=0\n",
    "    x=0\n",
    "    f = open('NateFollowers2.txt', 'w')\n",
    "    users=tweepy.Cursor(api.followers, screen_name=\"NateSilver538\",count=200).items()\n",
    "    while True:\n",
    "            try:\n",
    "                x=x+1\n",
    "                user=next(users)\n",
    "                i=i+1\n",
    "                print \"@\" + user.screen_name\n",
    "                followers.append(user.screen_name)\n",
    "                f.write(user.screen_name+'\\n')\n",
    "                if x>2900:\n",
    "                    x=0\n",
    "                    time.sleep(15*60)\n",
    "            except (tweepy.TweepError) as ex:\n",
    "                time.sleep(60*16)\n",
    "                pass\n",
    "            except (StopIteration):\n",
    "                break\n",
    "\n",
    "    \n",
    "followers=[]\n",
    "oauth_login()\n",
    "follow()\n",
    "\n",
    "\n",
    "#Nate Silver first 20 followers\n",
    "import twitter\n",
    "import tweepy\n",
    "import time\n",
    "#---------------------------------------------\n",
    "# Define a Function to Login Twitter API\n",
    "def oauth_login():\n",
    "    global api\n",
    "    auth = tweepy.OAuthHandler('bGCHZfPeuZ5YT6K1sKgQAEc3i','30WeyVyJBXH4I2VurEahvxVnfgIS6ID28a19659da8u8Fjy8j6' )\n",
    "    auth.set_access_token('833717288-1SOnSQSwRxxa3pRypHrYicro3t8rEvmPbKTm0hay','vAi4UscaZZ78awDpkdnd7ZFTzKTRovrM6wi0SlVmKz8Mn')\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "def friends():\n",
    "    try:\n",
    "        f = open('NateFriends.txt', 'w')\n",
    "        i=0\n",
    "        for user in tweepy.Cursor(api.friends, screen_name=\"NateSilver538\",count=200).items():\n",
    "            Natefollowers.loc[i]=[user.id,user.screen_name]\n",
    "            i=i+1\n",
    "            f.write(user.screen_name+'\\n')\n",
    "        f.close()        \n",
    "    except tweepy.TweepError, e:\n",
    "            print e\n",
    "\n",
    "\n",
    "Natefollowers=pd.DataFrame(columns=['ID','Screen_Name'])\n",
    "oauth_login()\n",
    "friends()\n",
    "Natefollowers[1:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "# nate silver friend FiveThirtyEight friends\n",
    "import twitter\n",
    "import tweepy\n",
    "import time\n",
    "import pandas as pd\n",
    "#---------------------------------------------\n",
    "# Define a Function to Login Twitter API\n",
    "def oauth_login():\n",
    "    global api\n",
    "    auth = tweepy.OAuthHandler('bGCHZfPeuZ5YT6K1sKgQAEc3i','30WeyVyJBXH4I2VurEahvxVnfgIS6ID28a19659da8u8Fjy8j6' )\n",
    "    auth.set_access_token('833717288-1SOnSQSwRxxa3pRypHrYicro3t8rEvmPbKTm0hay','vAi4UscaZZ78awDpkdnd7ZFTzKTRovrM6wi0SlVmKz8Mn')\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "def friends():\n",
    "    try:\n",
    "        f = open('538Friends.txt', 'w')\n",
    "        i=0\n",
    "        for user in tweepy.Cursor(api.friends, screen_name=\"FiveThirtyEight\",count=200).items():\n",
    "            Fivefollowers.loc[i]=[user.id,user.screen_name]\n",
    "            i=i+1\n",
    "            f.write(user.screen_name+'\\n')\n",
    "        f.close()        \n",
    "    except tweepy.TweepError, e:\n",
    "            print e\n",
    "\n",
    "\n",
    "Fivefollowers=pd.DataFrame(columns=['ID','Screen_Name'])\n",
    "oauth_login()\n",
    "friends()\n",
    "Fivefollowers[1:20]\n",
    "\n",
    "\n",
    "#Finding mutual friends\n",
    "z=[]\n",
    "for x in range(len(Fivefollowers)):\n",
    "    m=Fivefollowers.loc[x,'Screen_Name']\n",
    "    for y in range(len(Natefollowers)):\n",
    "        if Natefollowers.loc[y,'Screen_Name']==m:\n",
    "            z.append(m)\n",
    "            break\n",
    "#printing mutual friends\n",
    "\n",
    "Mutuals=pd.DataFrame(z,columns=['Screen_Name'])\n",
    "Mutuals\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*------------------------\n",
    "\n",
    "# Problem 4: Business question \n",
    "\n",
    "Run some additional experiments with your data to gain familiarity with the twitter data and twitter API.\n",
    "\n",
    "* Come up with a business question that Twitter data could help answer.\n",
    "* Decribe the business case.\n",
    "* How could Twitter data help a company decide how to spend its resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Your code starts here\n",
    "#   Please add comments or text cells in between to explain the general idea of each block of the code.\n",
    "#   Please feel free to add more cells below this cell if necessary\n",
    "\n",
    "#Extracted many files in this way\n",
    "\n",
    "import csv\n",
    "import tweepy\n",
    "import tweepy.error\n",
    "import time\n",
    "global api\n",
    "auth = tweepy.OAuthHandler('bGCHZfPeuZ5YT6K1sKgQAEc3i','30WeyVyJBXH4I2VurEahvxVnfgIS6ID28a19659da8u8Fjy8j6' )\n",
    "auth.set_access_token('833717288-1SOnSQSwRxxa3pRypHrYicro3t8rEvmPbKTm0hay','vAi4UscaZZ78awDpkdnd7ZFTzKTRovrM6wi0SlVmKz8Mn')\n",
    "api = tweepy.API(auth)\n",
    "cricTweet = tweepy.Cursor(api.search, q='PokemonGo playing',count=200).items()\n",
    "x=0\n",
    "tweets_playing=[]\n",
    "with open('Tweets_Playing.csv', 'wb') as csvfile:\n",
    "    fieldnames = ['tweets', 'retweets_count','Location','Time']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            x=x+1\n",
    "            user=next(cricTweet)\n",
    "            tweets.append(user.text)\n",
    "            print \"Downloaded.... %s \"%(len(tweets))\n",
    "            writer.writerow({'tweets': user.text.encode('utf-8'), 'retweets_count': user.retweet_count,'Location':user.user.time_zone,'Time':user.created_at})\n",
    "            if x>2900:\n",
    "                x=0\n",
    "                time.sleep(900)\n",
    "        except (tweepy.TweepError) as ex:\n",
    "            time.sleep(60*16)\n",
    "            pass\n",
    "        except StopIteration:\n",
    "            break\n",
    "print tweets\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#replace similar places bby single place\n",
    "df=df.replace(['America/Chicago','America/New_York','America/Toronto','America/Phoenix','America/Los_Angeles','America/Los_Angeles','America/Guatemala','Mountain Time (US & Canada)','Eastern Time (US & Canada)','Central Time (US & Canada)','Eastern Time (US & Canada)','Pacific Time (US & Canada)'],'America')\n",
    "df=df.replace(['Asia/Calcutta','Asia/Jakarta','Asia/Manila','CST','Chennai','Kolkata'],'Asia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#group by places to get playing counts\n",
    "count=df.groupby('Location').agg('count')\n",
    "index=count.index\n",
    "count.plot(index,'Tweets',kind='bar')\n",
    "plt.title(\"People Playing Ratio (Server Allocation Ratio)\",fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#People playig ratio according to regions to solver server issue\n",
    "sortedcount=count.sort('Tweets',ascending=False)\n",
    "top10=sortedcount[1:10]\n",
    "index=top10.index\n",
    "color=['red','green','blue','orange','yellow','pink','purple','violet','aqua']\n",
    "top10.plot(index,'Tweets',kind='bar',color=color,fontsize=12,legend=False)\n",
    "plt.xticks(rotation=60)\n",
    "plt.ylabel('Measure of tweets',fontsize=15)\n",
    "plt.xlabel('') \n",
    "plt.title(\"People Playing Ratio (Top 10 Countries) (Server Allocation Ratio)\",fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read file\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df_pokemon_8=pd.read_csv('C:\\Users\\Deepan Sanghavi\\\\tweets_PokemonGo_eight.csv',sep=',',header=0)\n",
    "df_pokemon_6=pd.read_csv('C:\\Users\\Deepan Sanghavi\\\\tweets_PokemonGo_6.csv',sep=',',header=0)\n",
    "df_pokemon_5=pd.read_csv('C:\\Users\\Deepan Sanghavi\\\\PokemonGo_5.csv',sep=',',header=0)\n",
    "df_pokemon_4=pd.read_csv('C:\\Users\\Deepan Sanghavi\\\\tweets_PokemonGo_4.csv',sep=',',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pokemon fame decreasing\n",
    "import numpy as np\n",
    "months=['June','July','August','September']\n",
    "ybar=np.arange(len(months))\n",
    "plt.bar(ybar,[len(df_pokemon_8),len(df_pokemon_4),len(df_pokemon_5),len(df_pokemon_6),],align='center',color=['orange','purple','blue','yellow'])\n",
    "plt.xticks(ybar, months,fontsize=20)\n",
    "plt.ylabel('Number of tweets',fontsize=20)\n",
    "plt.xlabel('Months',fontsize=20)\n",
    "plt.title('Tweet counts Trends of PokemonGO',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read\n",
    "facebook=pd.read_csv('C:\\Users\\Deepan Sanghavi\\\\Facebook.csv',sep=',',header=0)\n",
    "tinder=pd.read_csv('C:\\Users\\Deepan Sanghavi\\\\Tinder1.csv',sep=',',header=0)\n",
    "Pokemon=pd.read_csv('C:\\Users\\Deepan Sanghavi\\\\PokemonGo_5.csv',sep=',',header=0)\n",
    "Twitter=pd.read_csv('C:\\Users\\Deepan Sanghavi\\\\Twitter.csv',sep=',',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pokemon vs socal media\n",
    "import numpy as np\n",
    "months=['Facebook','Pokemon','Tinder','Twitter']\n",
    "ybar=np.arange(len(months))\n",
    "plt.bar(ybar,[len(facebook),len(tinder),len(Pokemon),len(Twitter)],align='center',color=['red','green','blue','yellow'])\n",
    "plt.xticks(ybar, months,fontsize=20)\n",
    "plt.colors()\n",
    "plt.ylabel('Number of tweets',fontsize=20)\n",
    "plt.xlabel('Months',fontsize=20)\n",
    "plt.title('Tweet counts Trends of PokemonGO',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read file\n",
    "UK=pd.read_csv('C:\\Users\\Deepan Sanghavi\\\\UK.csv',sep=',',header=0)\n",
    "India=pd.read_csv('C:\\Users\\Deepan Sanghavi\\\\India.csv',sep=',',header=0)\n",
    "Singapore=pd.read_csv('C:\\Users\\Deepan Sanghavi\\\\Singapore.csv',sep=',',header=0)\n",
    "Japan=pd.read_csv('C:\\Users\\Deepan Sanghavi\\\\Japan.csv',sep=',',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "months=['India','Uk','Singapore','Japan']\n",
    "ybar=np.arange(len(months))\n",
    "plt.bar(ybar,[len(UK),len(India),len(Singapore),len(Japan)],align='center',color=['yellow','red','blue','green'])\n",
    "plt.xticks(ybar, months,fontsize=20)\n",
    "plt.colors()\n",
    "plt.ylabel('Tweets Frequency',fontsize=20)\n",
    "plt.xlabel('Countries',fontsize=20)\n",
    "plt.title('Tweet Frequency in selected country',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This code extract the timezone location with 6 most tweets based on PokemongoApp\n",
    "\n",
    "import json\n",
    "import operator \n",
    "from collections import Counter\n",
    "tweets = []\n",
    "\n",
    "for line in open('/Users/rohit/Downloads/pokemon.txt'):\n",
    "  try: \n",
    "    tweets.append(json.loads(line))\n",
    "  except:\n",
    "    pass\n",
    "texts = [tweet['text'] for tweet in tweets]\n",
    "\n",
    "mytext=''.join(texts)\n",
    "    \n",
    "wordlist = mytext.split()\n",
    "\n",
    "wordfreq = [(wordlist.count(w),w) for w in wordlist] # a list comprehension\n",
    "a=sorted(wordfreq, key=operator.itemgetter(0), reverse=True)\n",
    "\n",
    "new_d = []\n",
    "for x in a:\n",
    "    if x not in new_d:\n",
    "        new_d.append(x)\n",
    "        \n",
    "new_d[:10]\n",
    "\n",
    "\n",
    "country=[tweet['place']['country'] if tweet['place'] else None for tweet in tweets]\n",
    "userloc = [tweet['user']['location'] for tweet in tweets]\n",
    "usertimez=[tweet['user']['time_zone'] for tweet in tweets]\n",
    "useroffset=[tweet['user']['utc_offset'] for tweet in tweets]\n",
    "\n",
    "country=[tweet['place']['country'] if tweet['place'] else None for tweet in tweets]\n",
    "\n",
    "cord = [offsetloc for offsetloc in useroffset if offsetloc != None]\n",
    "res=Counter(cord)\n",
    "x=sorted(res.items(), key=lambda item: item[1],reverse=True)\n",
    "final=x[:6]\n",
    "list1, list2 = zip(*final)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.bar(range(len(list1)), list2, align='center')\n",
    "#plt.xticks(range(len(list1)), list1)\n",
    "\n",
    "#plt.show()\n",
    "timezone=[tweet['user']['time_zone'] for tweet in tweets]\n",
    "tz = [zone for zone in timezone if zone != None]\n",
    "res1=Counter(tz)\n",
    "y=sorted(res1.items(), key=lambda item: item[1],reverse=True)\n",
    "final_zone=y[:6]\n",
    "#list1, list2 = zip(*final)\n",
    "ls1,ls2=zip(*final_zone)\n",
    "colors = ['#624ea7', 'g', 'yellow', 'k', 'maroon','red']\n",
    "plt.bar(range(len(ls1)), ls2, align='center',color=colors)\n",
    "plt.xticks(range(len(ls1)), ls1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This code is used to plot graphs for Love_Pokemon vs Hate_Pokemon\n",
    "# and to plot the accidents on the basis of time_zone(location)\n",
    " \n",
    "pokemon_love=[]\n",
    "pokemon_hate=[]\n",
    "with open('Pokemon_Hate.csv', 'rb') as f:\n",
    "    reader = csv.reader(f,delimiter=',')\n",
    "    pokemon_hate = list(reader)\n",
    "with open('Pokemon_Love.csv', 'rb') as f:\n",
    "    reader = csv.reader(f,delimiter=',')\n",
    "    pokemon_love = list(reader)\n",
    "with open('Pokemon_Accidents.csv', 'rb') as f:\n",
    "    reader = csv.reader(f,delimiter=',')\n",
    "    robbery_data_list = list(reader)\n",
    "\n",
    "# print robbery_data_list\n",
    "# exit(0)\n",
    "pokemon_hate_vs_love=[]\n",
    "for i in range(len(pokemon_love)):\n",
    "        pokemon_hate_vs_love.append(\"Pokemon Love\")\n",
    "for i in range(len(pokemon_hate)):\n",
    "        pokemon_hate_vs_love.append(\"Pokemon Hate\")\n",
    "xdf=pd.DataFrame(pokemon_hate_vs_love)\n",
    "xdf.columns=['Love_vs_Hate']\n",
    "xx=xdf.index\n",
    "xdf.Love_vs_Hate.value_counts().plot(kind='pie')\n",
    "plt.show()\n",
    "\n",
    "for i in robbery_data_list:\n",
    "    temp= i[0]\n",
    "    for j in temp.strip().split():\n",
    "        if j.strip().startswith(\"@\"):\n",
    "            temp=temp.replace(j,\"\")\n",
    "        if \"RT\" in j.strip():\n",
    "            # print j\n",
    "            temp=temp.replace(j,\"\")\n",
    "            # print temp.replace(j,\"\")\n",
    "            # exit(0)\n",
    "    # print i\n",
    "    # exit(0)\n",
    "    retweet_list.append(i[2])\n",
    "    location_list.append(i[4])\n",
    "    # print temp\n",
    "    # exit(0)\n",
    "    temp=temp.strip()\n",
    "    processed_tweets.append(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",temp))\n",
    "templist=[]\n",
    "\n",
    "for i in range(len(processed_tweets)):\n",
    "    # if processed_tweets[i] not in templist:\n",
    "        templist.append([])\n",
    "        templist[i].append(processed_tweets[i])\n",
    "        templist[i].append(retweet_list[i])\n",
    "        templist[i].append(location_list[i])\n",
    "df=pd.DataFrame(templist)\n",
    "df.columns=['Tweets','Retweets','Location']\n",
    "\n",
    "# df=df.fillna(0)\n",
    "df=df[df['Location']!='']\n",
    "# print df\n",
    "# exit(0)\n",
    "#Top 10 popular tweets on the basis of retweets\n",
    "# print df.sort('Retweets',ascending=False).head(10)\n",
    "# exit(0)\n",
    "# finalData['retweet_count']=finalData['retweet_count'].astype(int)\n",
    "# print finalData['retweet_count']\n",
    "\n",
    "# print df\n",
    "# exit(0)\n",
    "df.drop_duplicates()\n",
    "df1=df.groupby(by='Location',sort=True).count().head(10)\n",
    "# print df1\n",
    "# exit(0)\n",
    "# exit(0)\n",
    "df1=df1.sort('Retweets',ascending=False).head(10)\n",
    "# print df1\n",
    "print \"--------------\"\n",
    "# df1.columns=['Region','count']\n",
    "# print df1\n",
    "# exit(0)\n",
    "\n",
    "objects=df1['Retweets']\n",
    "# print objects\n",
    "# exit(0)\n",
    "x=df1.index\n",
    "df1.plot(x, 'Tweets', kind='bar')\n",
    "# plt.xticks(x, df1['Retweets'])\n",
    "# print x\n",
    "plt.show()\n",
    "# print df\n",
    "exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*-----------------\n",
    "# Done\n",
    "\n",
    "All set! \n",
    "\n",
    "** What do you need to submit?**\n",
    "\n",
    "* **Notebook File**: Save this IPython notebook, and find the notebook file in your folder (for example, \"filename.ipynb\"). This is the file you need to submit. Please make sure all the plotted tables and figures are in the notebook. If you used \"ipython notebook --pylab=inline\" to open the notebook, all the figures and tables should have shown up in the notebook.\n",
    "\n",
    "\n",
    "* **PPT Slides**: please prepare PPT slides (for 10 minutes' talk) to present about the case study . We will ask two teams which are randomly selected to present their case studies in class for this case study. \n",
    "\n",
    "* ** Report**: please prepare a report (less than 10 pages) to report what you found in the data.\n",
    "    * What data you collected? \n",
    "    * Why this topic is interesting or important to you? (Motivations)\n",
    "    * How did you analyse the data?\n",
    "    * What did you find in the data? \n",
    " \n",
    "     (please include figures or tables in the report, but no source code)\n",
    "\n",
    "Please compress all the files in a zipped file.\n",
    "\n",
    "\n",
    "** How to submit: **\n",
    "\n",
    "        Please submit through email to Prof. Paffenroth (rcpaffenroth@wpi.edu) *and* the TA Wen Liu (wliu3@wpi.edu).\n",
    "        \n",
    "** Note: Each team just needs to submits one submission **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading Criteria:\n",
    "\n",
    "** Totoal Points: 120 **\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Notebook:  **\n",
    "    Points: 80\n",
    "\n",
    "\n",
    "    -----------------------------------\n",
    "    Qestion 1:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    (1) Select a topic that you are interested in.\n",
    "    Points: 6 \n",
    "    \n",
    "    (2) Use Twitter Streaming API to sample a collection of tweets about this topic in real time. (It would be recommended that the number of tweets should be larger than 200, but smaller than 1 million. Please check whether the total number of tweets collected is larger than 200?\n",
    "    Points: 10 \n",
    "    \n",
    "    \n",
    "    (3) Store the tweets you downloaded into a local file (txt file or json file)\n",
    "    Points: 4 \n",
    "    \n",
    "    \n",
    "    -----------------------------------\n",
    "    Qestion 2:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    1. Word Count\n",
    "\n",
    "    (1) Use the tweets you collected in Problem 1, and compute the frequencies of the words being used in these tweets.\n",
    "    Points: 4 \n",
    "\n",
    "    (2) Plot a table of the top 30 words with their counts \n",
    "    Points: 4 \n",
    "    \n",
    "    2. Find the most popular tweets in your collection of tweets\n",
    "    plot a table of the top 10 tweets that are the most popular among your collection, i.e., the tweets with the largest number of retweet counts.\n",
    "    Points: 4 \n",
    "    \n",
    "    3. Find the most popular Tweet Entities in your collection of tweets\n",
    "\n",
    "    (1) plot a table of the top 10 hashtags, \n",
    "    Points: 4 \n",
    "\n",
    "    (2) top 10 user mentions that are the most popular in your collection of tweets.\n",
    "    Points: 4 \n",
    "    \n",
    "    \n",
    "    -----------------------------------\n",
    "    Qestion 3:\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "    \n",
    "    (1) choose a popular twitter user who has many followers, such as \"ladygaga\".\n",
    "    Points: 4 \n",
    "\n",
    "    (2) Get the list of all friends and all followers of the twitter user.\n",
    "    Points: 4 \n",
    "\n",
    "    (3) Plot 20 out of the followers, plot their ID numbers and screen names in a table.\n",
    "    Points: 4 \n",
    "\n",
    "    (4) Plot 20 out of the friends (if the user has more than 20 friends), plot their ID numbers and screen names in a table.\n",
    "    Points: 4 \n",
    "    \n",
    "    (5) Compute the mutual friends within the two groups, i.e., the users who are in both friend list and follower list, plot their ID numbers and screen names in a table\n",
    "    Points: 4 \n",
    "  \n",
    "    -----------------------------------\n",
    "    Qestion 4:  Business question\n",
    "    Points: 20\n",
    "    -----------------------------------\n",
    "        Novelty: 10\n",
    "        Interestingness: 10\n",
    "    -----------------------------------\n",
    "    Run some additional experiments with your data to gain familiarity with the twitter data ant twitter API.  Come up with a business question and describe how Twitter data can help you answer that question.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Report: communicate the results**\n",
    "    Points: 20\n",
    "\n",
    "(1) What data you collected?\n",
    "    Points: 5 \n",
    "\n",
    "(2) Why this topic is interesting or important to you? (Motivations)\n",
    "    Points: 5 \n",
    "\n",
    "(3) How did you analyse the data?\n",
    "    Points: 5 \n",
    "\n",
    "(4) What did you find in the data?\n",
    "(please include figures or tables in the report, but no source code)\n",
    "    Points: 5 \n",
    "\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "** Slides (for 10 minutes of presentation): Story-telling **\n",
    "    Points: 20\n",
    "\n",
    "\n",
    "1. Motivation about the data collection, why the topic is interesting to you.\n",
    "    Points: 5 \n",
    "\n",
    "2. Communicating Results (figure/table)\n",
    "    Points: 10 \n",
    "\n",
    "3. Story telling (How all the parts (data, analysis, result) fit together as a story?)\n",
    "    Points: 5 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
